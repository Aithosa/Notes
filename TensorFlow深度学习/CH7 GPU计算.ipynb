{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH7 GPU计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 TensorFlow 的GPU 管理\n",
    "在TensorFlow中，支持的设备被表示为字符串。\n",
    "* /cup:0：你机器中的CPU\n",
    "* /gpu:0：你机器中的GPU（如果有一个的话）\n",
    "* /gpu:1：你机器中的第二个GPU，等等。\n",
    "\n",
    "当一个操作被分配给GPU设备时，执行流是有优先级的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程序示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要在TensorFlow程序中使用GPU，只需在设置操作后输入如下语句：\n",
    "<br>`with tf.device(\"/gpu:0\"):`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以写一段程序，查看你的操作和张量被分配到哪一个设备。为实现这一操作，使用下述命令创建一个会话，将log_device_placement参数设置为True："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_device_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后确定参数n，即需要执行的乘法次数：\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 之后创建一个随机的大型矩阵。A和B的大小分别为10 000×10 000。\n",
    "# 使用NumPy中的rand函数执行这一操作：\n",
    "A = np.random.rand(10000, 10000).astype('float32')\n",
    "B = np.random.rand(10000, 10000).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面的数组将用于存储运算结果：\n",
    "c1 = []\n",
    "c2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处定义内核矩阵乘法函数，将由GPU执行：\n",
    "def matpow(M, n):\n",
    "    if n < 1:\n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前提到过，必须设置使用哪个GPU，以及用此GPU执行何种操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本例中，GPU将计算An+Bn，并将结果保存在c1中：\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有元素的和，即An+Bn，储存在c1中。求和操作由CPU执行，因此我们定义如下：\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c1)\n",
    "\n",
    "# datetime类统计代码的执行时间：\n",
    "t1_1 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    sess.run(sum, {a:A, b:B})\n",
    "t2_1 = datetime.datetime.now()\n",
    "\n",
    "# 运算时间由以下语句显示：\n",
    "print(\"GPU computation time: \" + str(t2_1-t1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "log_device_placement = True\n",
    "n = 10\n",
    "A = np.random.rand(10000, 10000).astype('float32')\n",
    "B = np.random.rand(10000, 10000).astype('float32')\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: #Abstract cases where n < 1\n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "with tf.device('/gpu:0'): # For CPU use /cpu:0\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))\n",
    "\n",
    "# If the below code does not work use '/job:localhost/replica:0/task:0/cpu:0' as the GPU device\n",
    "with tf.device('/cpu:0'):\n",
    "  sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n",
    "\n",
    "t1_1 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, \n",
    "                                      log_device_placement=log_device_placement)) as sess:\n",
    "     sess.run(sum, {a:A, b:B})\n",
    "t2_1 = datetime.datetime.now()\n",
    "\n",
    "# 运算时间由以下语句显示：\n",
    "print(\"GPU computation time: \" + str(t2_1-t1_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 在多GPU 系统上分配单个GPU\n",
    "如果你的系统里有超过一个GPU，那么TensorFlow会默认选取ID最小的那一块。如果你希望程序在不同的GPU上运行，那么需要进行手动设置，明确指定所用GPU。\n",
    "\n",
    "例如，可以使用前面讲过的代码更改GPU分配："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过这种方式，我们让GPU执行了内核函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果希望在指定设备不存在的情况下，TensorFlow能够自动选择已有的、支持的设备运行操作，\n",
    "# 那么可以将allow_soft_placement参数设置为True：\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                      log_device_placement=log_device_placement)) as sess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.9 使用多个GPU\n",
    "如果你希望在多个GPU上运行TensorFlow，那么可以在构建模型时将特定代码段分配给不同GPU。\n",
    "\n",
    "例如，如果你有两个GPU，那么可以将前面的代码进行如下分割，将第一个矩阵运算分配给第一个CPU。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c1.append(matpow(a, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个矩阵运算被分配给第二个CPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c1.append(matpow(b, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，CPU会管理程序的结果。另外需要注意，我们使用了共享的c1数组来收集结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c1)\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
