{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Keras中的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Keras中设定了两类深度学习模型：一类是**序列模型（Sequential类）**；一类是**通用模型（Model类）**。\n",
    "\n",
    "其差异在于不同的拓扑结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 序列模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "序列模型属于通用模型的一个子类，因为很常见，所以这里单独列出来进行介绍。\n",
    "<br>这种模型各层之间是依次顺序的线性关系，在第k层和第k+1层之间可以加上各种元素来构造神经网络。这些元素可以通过一个列表来制定，然后作为参数传递给序列模型来生成相应的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Dense(32, input_shape=(784,)),Activation('relu'), Dense(10), Activation('softmax')]\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除一开始直接在一个列表中指定所有元素外，也可以像下面这个例子一样逐层添加："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 通用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通用模型可以用来设计非常复杂、任意拓扑结构的神经网络，例如有向无环网络、共享层网络等。\n",
    "\n",
    "类似于序列模型，通用模型通过**函数化的应用接口**来定义模型。\n",
    "\n",
    "使用函数化的应用接口有多个好处，比如：\n",
    "1. 决定函数执行结果的唯一要素是其返回值，而决定返回值的唯一要素则是其参数，这大大减轻了代码测试的工作量；\n",
    "2. 因为函数式语言是一个形式系统，只要能用数学运算表达的就能用这种语言来表述，因此，只要在数学上是等价的，那么机器就可以使用等价的但是效率更高的代码来代替效率低的代码而不影响结果。这一方面方便了分析师写程序；另一方面又从数学上保证了代码效率，实现了人工时间和机器时间的双重高效。\n",
    "\n",
    "*有兴趣的读者可以去阅读一些函数式编程的书来帮助理解。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在**函数式编程**中，操作对象都是函数，函数也作为参数来传递，因此可以很方便地转化为一个函数接口供其他函数调用。\n",
    "<br>比如有一个计算任意两个实数乘积的函数：`double times(double x，double y)`，那么`Triple = double times(double x，3)`就定义了一个计算3倍数的新函数，只需要一个参数，从程序的角度来看会继续调用times函数，并把第二个参数设置为3，创建一个times函数的封装函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在**通用模型**中，使用同样的方法来定义模型的要素和结构。在定义的时候，从输入的多维矩阵开始，然后定义各层及其要素，最后定义输出层。将输入层和输出层作为参数纳入通用模型中就可以定义一个模型对象，并进行编译和拟合。\n",
    "\n",
    "下面的例子来自于Keras手册，用一个全连接神经网络拟合一个手写阿拉伯数字的分类模型。输入的数据是28×28的图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，载入相关模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，定义输入层Input，主要是为了定义输入的多维矩阵的尺寸。在这里因为每一个图像都被拉平为784个像素点的向量，因此这个多维矩阵的尺寸为（784，）的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在定义各个连接层，包括相应的激活函数。假设从输入层开始，定义两个隐含层，都有64个神经元，都使用relu激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(64, activation='relu')(input)\n",
    "x = Dense(64, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个隐含层使用输入层作为参数，而第二个隐含层使用第一个隐含层作为参数，这跟上面的封装例子类似，体现了函数式编程的优点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来定义输出层，使用最近的隐含层作为参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Dense(10,  activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有要素都齐备以后，就可以定义模型对象了，参数很简单，分别是输入和输出，其中输出包含了中间的各种信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = input, outputs = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，当模型对象定义完成以后，就可以进行编译了，并对数据进行拟合。拟合的时候也有两个参数，分别对应于输入和输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmprop',loss='categorical_crossentropy', metrics=['accuracy'] )\n",
    "model.fit(data,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到，对于序列模型和通用模型，它们的主要差异在于如何定义从输入层到输出层的各层结构。\n",
    "1. 首先，在序列模型里，是先定义序列模型对象的；而在通用模型中是先定义从输入层到输出层各层要素的，包括尺寸结构。\n",
    "2. 其次，在序列模型中，当有了一个模型对象以后，可以通过add方法对其依次添加各层信息，包括激活函数和网络尺寸来定义整个神经网络；而在通用模型中，是通过不停地封装含有各层网络结构的函数作为参数来定义网络结构的。\n",
    "3. 最后，在序列模型中，各层只能依次线性添加；而在通用模型中，因为采用了封装的概念，可以在原有的网络结构上应用新的结构来快速生成新的模型，因此灵活度要高很多，特别是在具有多种类型的输入数据的情况下，比如在Keras手册中就举了一个教神经网络看视频进行自然语言问答的例子。在这个例子中，输入数据有两种：一是视频图像；二是自然语言的提问。首先通过构造多层卷积神经网络使用序列模型来对图像编码，然后将这个模型放入TimeDistributed函数中建立视频编码，最后使用LSTM对编码建模，同时对自然语言也进行从文字到向量的转换，在合并两个网络以后，将合并的网络作为参数输入下一个全连接层进行计算，并输出可能的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然对于大部分工作，序列模型已经能够有效应对，但是函数式接口的通用模型为分析师提供了更强大的工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
