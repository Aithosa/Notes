{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本代码应用movielens 的数据集，讲解如何利用深度学习构造推荐系统模型。推荐系统的目标函数有很多，比如推荐评分最高的，或者推荐点击率最高的等等。有时候我们还会兼顾推荐内容的多样性。我们在这里讲解的是最根本的基于用户给内容打分的情形。这里的核心思想是对用户和内容建模，从而预测用户对未看过内容的打分。推荐系统进而会把预测的高分内容呈现给用户。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Dense, Reshape\n",
    "from keras.layers.merge import Dot, Concatenate\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依常规，我们首先得进行探索性分析，看看数据集和评分分布长什么样子的。借此我们还要计算评分稀疏性，因为所有的推荐系统都是基于大量缺失数据的。在这里，我们的思路是预测整个评分表，把缺失数据还原。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6040, 3952, 1000209]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEvx0wRr7eaagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e25d5d8c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.58156445303\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('./data/ratings.dat', sep = '::', \\\n",
    "    engine='python',names = ['user_id','movie_id','rating','timestamp'])\n",
    "n_users = np.max(ratings['user_id'])\n",
    "n_movies = np.max(ratings['movie_id'])\n",
    "print([n_users, n_movies, len(ratings)])\n",
    "\n",
    "plt.hist(ratings['rating'])\n",
    "plt.show()\n",
    "print(np.mean(ratings['rating']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们进行对用户和内容的建模，使用的是我们熟悉的Emdbedding思想。我们使用的Embedding维度为128。读者可以自行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128    \n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(n_users + 1, k, input_length = 1))\n",
    "model1.add(Reshape((k,)))\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(n_movies + 1, k, input_length = 1))\n",
    "model2.add(Reshape((k,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input('embedding_2_input', [#], [1]),\n",
       " Composite(UserFunction): Input('embedding_2_input', [#], [1]) -> Output('UserDefinedFunction21_Output_0', [#], [128]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input, model2.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的思路是通过计算用户和内容的向量乘积，得出评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "m = Dot(axes=1)([model1.output, model2.output])\n",
    "model_output = m\n",
    "model = Model([model1.input, model2.input], model_output)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "#model.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "#model.compile(loss = 'mse', optimizer = 'adagrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好训练数据，代入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ratings['user_id'].values\n",
    "movies = ratings['movie_id'].values\n",
    "X_train = [users, movies]\n",
    "y_train = ratings['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 4.2107    \n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 16s - loss: 0.8144    \n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.7382    \n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.6734    \n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.6095    \n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.5409    \n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.4706    \n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.4064    \n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.3514    \n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.3074    \n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.2733    \n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.2472    \n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.2271    \n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.2111    \n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1985    \n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1880    \n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1791    \n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1716    \n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1654    \n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1597    \n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1548    \n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1505    \n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1466    \n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1432    \n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1400    \n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1371    \n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 16s - loss: 0.1346    \n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1322    \n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1300    \n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1280    \n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1262    \n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1245    \n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1230    \n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1214    \n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1201    \n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1187    \n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1176    \n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1164    \n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1154    \n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 22s - loss: 0.1143    \n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1134    \n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1124    \n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1117    \n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1107    \n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1100    \n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1092    \n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1087    \n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1078    \n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1073    \n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 15s - loss: 0.1067    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e24437bb38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 500, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看下模型预测效果。注意到我们这里作为演示，只做了模型拟合程度，读者可以把原始数据集分成训练，校对和测试数据集，评估模型准确率。我们这里看一个例子，预测第10号用户对第99号内容的打分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=10\n",
    "j=99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.43756032]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们计算模型在训练数据集上的均方差。这告诉我们拟合程度的好坏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000064/1000209 [============================>.] - ETA: 0s0.0862894641702\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(x=X_train, y = y_train, batch_size=128)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们接下来构建深度学习模型。这里的想法与上述稍微不同。我们把用户和内容的Embedding合并在一起（concatenate)，作为输入层，然后通过网络模型提取一层层特征，最后用线性变换得出预测评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "input_1 = Input(shape=(1,))\n",
    "model1 = Embedding(n_users + 1, k, input_length = 1)(input_1)\n",
    "model1 = Reshape((k,))(model1)\n",
    "input_2 = Input(shape=(1,))\n",
    "model2 = Embedding(n_movies + 1, k, input_length = 1)(input_2)\n",
    "model2 = Reshape((k,))(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input('input_1', [#], [1]),\n",
       " Input('input_2', [#], [1]),\n",
       " Composite(UserFunction): Input('input_1', [#], [1]) -> Output('UserDefinedFunction416242_Output_0', [#], [128]),\n",
       " Composite(UserFunction): Input('input_2', [#], [1]) -> Output('UserDefinedFunction416252_Output_0', [#], [128]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1,input_2, model1,model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Concatenate()([model1, model2])\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(k, activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/4), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/16), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "yhat = Dense(1, activation = 'linear')(model)\n",
    "model = Model([input_1, input_2], yhat)\n",
    "model.compile(loss = 'mse', optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前一样，我们准备好训练数据集，代入模型训练。并通过均方差计算模型的拟合程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ratings['user_id'].values\n",
    "movies = ratings['movie_id'].values\n",
    "label = ratings['rating'].values\n",
    "X_train = [users, movies]\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.9312    \n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.9126    \n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.9052    \n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8984    \n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8906    \n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8846    \n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8800    \n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8752    \n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8710    \n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8686    \n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8642    \n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8622    \n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8603    \n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8575    \n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 14s - loss: 0.8559    \n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 14s - loss: 0.8534    \n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 14s - loss: 0.8502    \n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8479    \n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8477    \n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8438    \n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8423    \n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8397    \n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8377    \n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8355    \n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8355    \n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8330    \n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8305    \n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8285    \n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8263    \n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8255    \n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8237    \n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8218    \n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8205    \n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8195    \n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8193    \n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8162    \n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8161    - ETA: \n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8145    \n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8138    \n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8131    - ETA: \n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8107    \n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8099    \n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8092    \n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8078    \n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8063    \n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8063    \n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8052    \n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8044    \n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8041    \n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 13s - loss: 0.8029    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e259bcb908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 1000, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999296/1000209 [============================>.] - ETA: 0s0.68989211486\n"
     ]
    }
   ],
   "source": [
    "i,j = 10,99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])\n",
    "\n",
    "mse = model.evaluate(x=X_train, y=y_train, batch_size=128)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
